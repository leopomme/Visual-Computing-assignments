{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIC - Introduction to Visual Computing\n",
    "\n",
    "## Low-Level Vision, Image Filtering, Edge Detection.\n",
    "\n",
    "During these exercises, you will become familiar with image processing and low level vision in `Python`.\n",
    "\n",
    "For the lab exercises use `jupyter` (or anything else at your own risk). It can be installed by issuing `pip install jupyter` on Linux after installing pip itself with `apt install python-pip`. Mac and Windows users can find the installation instructions online. The first thing that is needed is to import some libraries, such as `numpy`, `scipy`, `random` and `matplotlib` for visualization. If they are missing you can simply install them with e.g., `pip install numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Consider the filter `f = [1,3,2]` and the 1D image `I = [0,1,2,3,3,3,1,3,6]`. What is the result of `f*I`? Implement your own convolution and then compare it to `scipy.ndimage.convolve1d`. Pad the image with zeros at the boundaries if necessary. Plot the two signals and observe their difference. What does this filter do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = np.array([1, 3, 2])\n",
    "I = np.array([0, 1, 2, 3, 3, 3, 1, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "O = np.zeros_like(I)\n",
    "pad_I = np.pad(I, pad_width=1, mode='constant')\n",
    "\n",
    "for i in range(len(I)):\n",
    "    O[i] = np.sum(pad_I[i:i+3] * f[::-1])\n",
    "\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "O_np = convolve1d(I, f, mode='constant')\n",
    "print(O_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "ax.plot(O_np, color='orange')\n",
    "ax.scatter(range(len(O_np)), O_np, marker='o', color='orange')\n",
    "ax.plot(I, color='blue')\n",
    "ax.scatter(range(len(I)), I, marker='o', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Now let us pass to two dimensions. We read an image and the corresponding (human generated) ground truth of the image contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "mat = io.loadmat('12003.mat')\n",
    "bound = mat['groundTruth'][0, 2][0][0][1]\n",
    "\n",
    "image = plt.imread('12003.jpg')\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(bound, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercises below will be simplified if we work on a grayscale representation. We also normalise to a [0, 1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conversion to grayscale\n",
    "r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "img = (0.2989 * r + 0.5870 * g + 0.1140 * b) / 255.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Salt and pepper noise randomly sets each pixel to the minimum or maximum of the image range (here, 0 or 1). Implement a function with parameter $p$ to add salt and pepper noise to the grayscale `img`. Each pixel should become 0 with probability $p/2$, 1 with probability $p/2$, and stay unchanged with probaility $1 - p$. Use the `random.random` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def salt_and_pepper_noise(img, p):\n",
    "    \"\"\"\n",
    "    Adds salt and pepper noise to the image\n",
    "    p: probability of the noise\n",
    "    \"\"\"\n",
    "    assert 0 <= p and p <= 1  # valid probability\n",
    "    assert len(img.shape) == 2  # grayscale image\n",
    "    h, w = img.shape\n",
    "    \n",
    "    I_out = img.copy()\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if random() < p:\n",
    "                if random() < 0.5: \n",
    "                    I_out[i, j] = 0  # pepper\n",
    "                else:\n",
    "                    I_out[i, j] = 1  # salt\n",
    "    return I_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the result. Try adjusting the amount of salt and pepper. For best results, proceed to the next exercise with $p \\approx 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sp_img = salt_and_pepper_noise(img, 0.1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(sp_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-pass filters\n",
    "\n",
    "Low-pass filters attenuate high-frequency signals, and can be used for smoothing and noise removal. Here we will implement three such filters. Take some time to check the different results. Which filter behaves better and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1\n",
    "\n",
    "Implement a mean filter,\n",
    "\n",
    "$$\n",
    "M = 1/9 \\cdot \\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "as a `np.array` object to remove the salt and pepper noise from the image. Use the `scipy.ndimage.convolve` function to convolve the filter. Try changing the filter size. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "radius = 5\n",
    "MEAN_FILTER = (1 / radius ** 2) * np.ones((radius, radius))\n",
    "mean_img = convolve(sp_img, MEAN_FILTER, mode='constant')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(mean_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2\n",
    "\n",
    "Apply a Gaussian filter to the image. This time, use the `scipy.ndimage.gaussian_filter` function. Try adjusting the `sigma` parameter. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "gaussian_img = gaussian_filter(sp_img, sigma=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(gaussian_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Implement a median filter to denoise the image. Note that this filter is non-linear, so this time you will have to code the sliding-window process yourself. Can you think of an improvement to a simple sliding-window approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def median_filter(img, radius):\n",
    "    h, w = img.shape\n",
    "\n",
    "    I_out = img.copy()\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            I_out[i, j] = np.median(img[max(i-radius, 0):min(i+radius, h),\n",
    "                                        max(j-radius, 0):min(j+radius, w)])\n",
    "    return I_out\n",
    "\n",
    "median_img = median_filter(sp_img, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(median_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-pass filters\n",
    "\n",
    "High-pass filters promote high-frequency information, and can be used for image sharpening and edge detection. Here we implement two such filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1\n",
    "\n",
    "Implement the Laplacian filter,\n",
    "\n",
    "$$\\Delta I = \\frac{\\partial^2 I}{\\partial x^2} + \\frac{\\partial^2 I}{\\partial y^2} := I * \\Bigg(\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & 2 & -1 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "0 & 2 & 0 \\\\\n",
    "0 & -1 & 0\n",
    "\\end{bmatrix}\\Bigg)$$\n",
    "\n",
    "on the original image to detect the edges. Once more, you should use `scipy.ndimage.convolve` to perform the convolution. Perform the same using the smoothed images from a Gaussian filter. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LAPLACE_FILTER = np.array([[0, -1, 0],\n",
    "                           [-1, 4, -1],\n",
    "                           [0, -1, 0]])\n",
    "\n",
    "laplace_img = convolve(img, LAPLACE_FILTER, mode='constant')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(laplace_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2\n",
    "\n",
    "Implement the Sobel filters and apply them to `img` to detect the edges,\n",
    "\n",
    "$$G_x = I * \\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "2 & 0 & -2 \\\\\n",
    "1 & 0 & -1\n",
    "\\end{bmatrix}, G_y = I * \\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -2 & -1\n",
    "\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SOBEL_X = np.array([[+1, 0, -1],\n",
    "                    [+2, 0, -2],\n",
    "                    [+1, 0, -1]])\n",
    "\n",
    "SOBEL_Y = np.array([[+1, +2, +1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -1, -2]])\n",
    "\n",
    "sobel_x_img = convolve(img, SOBEL_X, mode='constant')\n",
    "sobel_y_img = convolve(img, SOBEL_Y, mode='constant')\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "axes[0].imshow(sobel_x_img, cmap='gray')\n",
    "axes[0].set_title('$G_x$')\n",
    "axes[1].imshow(sobel_y_img, cmap='gray')\n",
    "axes[1].set_title('$G_y$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.3\n",
    "\n",
    "Combine the Sobel gradient images to obtain the gradient magnitude image,\n",
    "\n",
    "$$G = \\sqrt{G_x^2 + G_y^2}$$\n",
    "\n",
    "Then, binarise this by choosing a suitable threshold in order to obtain a segmentation of the image edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "magnitude_img = np.sqrt(sobel_x_img ** 2 + sobel_y_img ** 2)\n",
    "\n",
    "# normalise image\n",
    "magnitude_img -= np.min(magnitude_img)\n",
    "magnitude_img /= np.max(magnitude_img)\n",
    "\n",
    "THRESHOLD = 0.2\n",
    "segmented_img = magnitude_img > THRESHOLD\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), ncols=2)\n",
    "axes[0].imshow(magnitude_img, cmap='gray')\n",
    "axes[0].set_title('$G$')\n",
    "axes[1].imshow(segmented_img, cmap='gray')\n",
    "axes[1].set_title('$G > T$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate the segmentation quality as compared with the ground truth image using `sklearn.metrics`. Try adjusting the threshold above. How do the evaluation metrics change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print('Precision:\\t %.02f' % precision_score(segmented_img.flatten(), bound.flatten()))\n",
    "print('Recall:\\t\\t %.02f' % recall_score(segmented_img.flatten(), bound.flatten()))\n",
    "print('F1 score:\\t %.02f' % f1_score(segmented_img.flatten(), bound.flatten()))\n",
    "print('Accuracy:\\t %.02f' % accuracy_score(segmented_img.flatten(), bound.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.4\n",
    "\n",
    "Try the different morphological operators in `scipy.ndimage` to post-process the segmented image, and improve the overall accuracy. Note, that despite the mathematical jargon, a dilation is really just a *max* filter, and an erosion is a *min* filter, akin to the median filter we coded before. The structuring element specifies the size and shape of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation, binary_erosion, binary_opening, binary_closing\n",
    "\n",
    "# Define structuring element\n",
    "selem = np.ones((2, 2))\n",
    "\n",
    "dilated_image = binary_dilation(segmented_img, selem)\n",
    "eroded_image = binary_erosion(segmented_img, selem)\n",
    "opened_image = binary_opening(segmented_img, selem)\n",
    "closed_image = binary_closing(segmented_img, selem)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
    "axes[0][0].imshow(dilated_image, cmap='gray')\n",
    "axes[0][0].set_title('Dilation')\n",
    "axes[0][1].imshow(eroded_image, cmap='gray')\n",
    "axes[0][1].set_title('Erosion')\n",
    "axes[1][0].imshow(opened_image, cmap='gray')\n",
    "axes[1][0].set_title('Opening')\n",
    "axes[1][1].imshow(closed_image, cmap='gray')\n",
    "axes[1][1].set_title('Closing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print('Precision:\\t %.02f' % precision_score(opened_image.flatten(), bound.flatten()))\n",
    "print('Recall:\\t\\t %.02f' % recall_score(opened_image.flatten(), bound.flatten()))\n",
    "print('F1 score:\\t %.02f' % f1_score(opened_image.flatten(), bound.flatten()))\n",
    "print('Accuracy:\\t %.02f' % accuracy_score(opened_image.flatten(), bound.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier analysis\n",
    "\n",
    "We will now perform the main low- and high-pass filter operations in frequency space using `scipy.fft` functions for Fourier analysis. First, let's plot the frequency representation of our grayscale image. We define a helper function `vis_fft` to visualise lower amplitude frequencies more easily. Notice, the transform is a complex-valued image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.fft import fft2, fftshift\n",
    "\n",
    "# Apply 2D fast Fourier transform algorithm\n",
    "fft_img = fft2(img)\n",
    "\n",
    "# Helper function for visualising low-intensity Fourier values\n",
    "def vis_fft(fft):\n",
    "    return np.log(np.abs(fft) + 1e-8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(vis_fft(fftshift(fft_img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1\n",
    "\n",
    "We form a 2D Gaussian $G$ in pixel space. Applying the convolution theorem,\n",
    "\n",
    "$$\\mathcal{F}(G * I) = \\mathcal{F}(G) \\cdot \\mathcal{F}(I),$$\n",
    "\n",
    "we multiply the frequency representation of the Gaussian $\\mathcal{F}(G)$ element-wise with that of the image, and visualise each. Note we apply the `fftshift` function to centerise the low frequencies. What is the shape of $\\mathcal{F}(G)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.fft import ifft2, ifftshift\n",
    "from scipy import signal\n",
    "\n",
    "# Outer product of Gaussians\n",
    "GAUSSIAN_FILTER = np.outer(signal.gaussian(img.shape[0], std=3),\n",
    "                           signal.gaussian(img.shape[1], std=3))\n",
    "\n",
    "# Transform Gaussian filter\n",
    "fft_gaussian = fft2(ifftshift(GAUSSIAN_FILTER))\n",
    "\n",
    "# By the convolution theorem!\n",
    "fft_convolved = fft_img * fft_gaussian\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), ncols=3)\n",
    "\n",
    "axes[0].imshow(GAUSSIAN_FILTER)\n",
    "axes[0].set_title('$G$')\n",
    "axes[1].imshow(vis_fft(fftshift(fft_gaussian)))\n",
    "axes[1].set_title('$\\mathcal{F}(G)$')\n",
    "axes[2].imshow(vis_fft(fftshift(fft_convolved)))\n",
    "axes[2].set_title('$\\mathcal{F}(G * I) = \\mathcal{F}(G) * \\mathcal{F}(I)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains is to apply the inverse FFT to recover the original image! What was the effect of the Gaussian kernel? How does it compare with that of **Exercise 4.2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "restored_img = ifft2(fft_convolved).real\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(restored_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "Mask (set to zero) the low frequencies of `fft_img` so as perform a high-pass filter in Fourier space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h, w = fft_img.shape\n",
    "r = 10\n",
    "\n",
    "fft_low_pass = fftshift(fft_img)\n",
    "\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        if np.sqrt((i - h / 2) ** 2 + (j - w / 2) ** 2) < r:\n",
    "            fft_low_pass[i, j] = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(vis_fft(fft_low_pass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally restore the image to pixel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "restored_img = ifft2(ifftshift(fft_low_pass)).real\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(restored_img, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
